/*
 * This source file was generated by the Gradle 'init' task
 */
package word.pronunciation;

import java.io.IOException;
import java.nio.ByteBuffer;
import java.nio.charset.StandardCharsets;
import java.time.Duration;
import java.time.LocalDateTime;
import java.time.format.DateTimeFormatter;
import java.util.HashMap;
import java.util.Map;

import org.apache.flink.api.common.eventtime.WatermarkStrategy;
import org.apache.flink.api.common.functions.AggregateFunction;
import org.apache.flink.api.common.serialization.DeserializationSchema;
import org.apache.flink.api.common.serialization.SerializationSchema;
import org.apache.flink.api.common.typeinfo.TypeInformation;
import org.apache.flink.api.common.typeinfo.Types;
import org.apache.flink.connector.base.DeliveryGuarantee;
import org.apache.flink.connector.kafka.sink.KafkaRecordSerializationSchema;
import org.apache.flink.connector.kafka.sink.KafkaSink;
import org.apache.flink.connector.kafka.source.KafkaSource;
import org.apache.flink.connector.kafka.source.enumerator.initializer.OffsetsInitializer;
import org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator;
import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
import org.apache.flink.streaming.api.windowing.assigners.SlidingEventTimeWindows;
import org.apache.flink.streaming.api.windowing.assigners.TumblingEventTimeWindows;

public class App {

        public static void main(String[] args) {
                // Flink 실행 환경 설정
                StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();

                // Kafka 소스 설정
                KafkaSource<Word> kafkaSource = KafkaSource.<Word>builder()
                                .setBootstrapServers("localhost:29092,localhost:39092,localhost:49092")
                                .setTopics("input-topic")
                                .setGroupId("flink-consumer-group")
                                .setStartingOffsets(OffsetsInitializer.earliest())
                                .setValueOnlyDeserializer(new WordDeserializationSchema()) // 메시지를 문자열로 직렬화
                                .build();

                SingleOutputStreamOperator<Word> wordStream = env.fromSource(kafkaSource,
                                WatermarkStrategy.forMonotonousTimestamps(), "Kafka Source");
                SingleOutputStreamOperator<WordPronunciation> pronunciationStream = wordStream
                                .keyBy(Word::getWord)
                                .window(TumblingEventTimeWindows.of(Duration.ofSeconds(1))) // 30초 간격 윈도우 설정
                                // .countWindow(10) // 10개 간격 윈도우 설정
                                // .window(SlidingEventTimeWindows.of(Duration.ofSeconds(60),
                                // Duration.ofSeconds(5))) // 60초 크기, 5초 슬라이드 간격
                                .aggregate(new WordCountAggregator());

                // Kafka Sink 설정
                KafkaSink<WordPronunciation> kafkaSink = KafkaSink.<WordPronunciation>builder()
                                .setBootstrapServers("localhost:29092,localhost:39092,localhost:49092")
                                .setRecordSerializer(KafkaRecordSerializationSchema.builder()
                                                .setTopic("output-topic") // 데이터를 전송할 Kafka 출력 토픽
                                                .setValueSerializationSchema(new WordPronunciationSerializationSchema()) // 데이터를
                                                                                                                         // 문자열로
                                                                                                                         // 직렬화
                                                .build())
                                .setDeliveryGuarantee(DeliveryGuarantee.AT_LEAST_ONCE) // 최소 1회 전송 보장
                                .build();

                // Kafka Sink에 데이터 스트림 연결
                pronunciationStream.sinkTo(kafkaSink);

                // Flink 작업 실행
                try {
                        env.execute("Kafka Word Splitter");
                } catch (Exception e) {
                        e.printStackTrace();
                }
        }

        public static class WordPronunciation {
                private String word;
                private int count;

                public WordPronunciation() {

                }

                public WordPronunciation(String word, int count) {
                        this.word = word;
                        this.count = count;
                }

                public String getWord() {
                        return word;
                }

                public int getCount() {
                        return count;
                }
        }

        public static class WordCountAggregator
                        implements AggregateFunction<Word, Map<String, Integer>, WordPronunciation> {

                @Override
                public Map<String, Integer> createAccumulator() {
                        return new HashMap<>();
                }

                @Override
                public Map<String, Integer> add(Word value, Map<String, Integer> accumulator) {
                        accumulator.put(value.getWord(), accumulator.getOrDefault(value.getWord(), 0) + 1);
                        return accumulator;
                }

                @Override
                public WordPronunciation getResult(Map<String, Integer> accumulator) {
                        return accumulator.entrySet()
                                        .stream()
                                        .map(entry -> new WordPronunciation(entry.getKey(), entry.getValue()))
                                        .findFirst()
                                        .orElse(null);
                }

                @Override
                public Map<String, Integer> merge(Map<String, Integer> a, Map<String, Integer> b) {
                        b.forEach((key, value) -> a.merge(key, value, Integer::sum));
                        return a;
                }
        }

        public static class Word {
                private String word;
                private int weight;
                private LocalDateTime timestamp;

                public Word(String word, int weight, LocalDateTime timestamp) {
                        this.word = word;
                        this.weight = weight;
                        this.timestamp = timestamp;
                }

                public Word() {
                        // 기본 생성자 필요
                }

                public void setWord(String word) {
                        this.word = word;
                }

                public void setWeight(int weight) {
                        this.weight = weight;
                }

                public void setTimestamp(LocalDateTime timestamp) {
                        this.timestamp = timestamp;
                }

                public String getWord() {
                        return word;
                }

                public int getWeight() {
                        return weight;
                }

                public LocalDateTime getTimestamp() {
                        return timestamp;
                }
        }

        public static class WordDeserializationSchema implements DeserializationSchema<Word> {

                private static final DateTimeFormatter formatter = DateTimeFormatter.ISO_LOCAL_DATE_TIME;

                @Override
                public Word deserialize(byte[] message) throws IOException {
                        try {
                                ByteBuffer buffer = ByteBuffer.wrap(message);

                                // 단어의 길이를 읽고, 그에 맞춰 단어 읽기
                                int wordLength = buffer.getInt();
                                byte[] wordBytes = new byte[wordLength];
                                buffer.get(wordBytes);
                                String word = new String(wordBytes, StandardCharsets.UTF_8);

                                // 가중치를 읽기
                                int weight = buffer.getInt();

                                // 타임스탬프의 길이를 읽고, 그에 맞춰 타임스탬프 읽기
                                int timestampLength = buffer.getInt();
                                byte[] timestampBytes = new byte[timestampLength];
                                buffer.get(timestampBytes);
                                String timestampStr = new String(timestampBytes, StandardCharsets.UTF_8);
                                LocalDateTime timestamp = LocalDateTime.parse(timestampStr, formatter);

                                return new Word(word, weight, timestamp);
                        } catch (Exception e) {
                                throw e;
                        }
                }

                @Override
                public boolean isEndOfStream(Word nextElement) {
                        return false;
                }

                @Override
                public TypeInformation<Word> getProducedType() {
                        return Types.POJO(Word.class);
                }
        }

        public static class WordPronunciationSerializationSchema implements SerializationSchema<WordPronunciation> {

                @Override
                public byte[] serialize(WordPronunciation element) {
                        // "word,count" 형식의 CSV 문자열로 직렬화
                        String serializedString = element.getWord() + "," + element.getCount();
                        return serializedString.getBytes(StandardCharsets.UTF_8);
                }
        }
}
